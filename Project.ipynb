{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1aafa1c-4163-400c-a5fa-b46382706b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\utkar\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a3a900-dadd-4442-8ebd-207998db681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = \"C:\\\\Users\\\\utkar\\\\kaggle.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75efb210-a05c-4a34-9493-867208521284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"utkarshkohli821\"\n",
    "os.environ['KAGGLE_KEY'] = \"1228f249c89a291ddab0e1866129f12d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "614eb1e8-2a12-4c1b-9d35-8e92d586a9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset\n",
      "License(s): CC-BY-NC-SA-4.0\n",
      "fake-and-real-news-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d clmentbisaillon/fake-and-real-news-dataset\n",
    "!unzip fake-and-real-news-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27e32d39-2e1a-4e69-8771-6b1cba2eb421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"fake-and-real-news-dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"fake_news_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "250f5b13-38aa-4c95-b798-c74cd0b67d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_fake = pd.read_csv(\"fake_news_data/Fake.csv\")\n",
    "df_real = pd.read_csv(\"fake_news_data/True.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91481514-1196-45a5-9d0b-d9558a51e39f",
   "metadata": {},
   "source": [
    "\n",
    "The main changes I made:\n",
    "1. Added pip install command for the missing dependency\n",
    "2. Added the missing import for df_fake\n",
    "3. Updated the training arguments to use newer parameter names (evaluation_strategy instead of do_eval and eval_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "087eba01-07c5-4fa9-850f-13c7b992fce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'accelerate\": Expected package name at the start of dependency specifier\n",
      "    'accelerate\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "# First, install the required dependencies\n",
    "!pip install 'accelerate>=0.26.0'\n",
    "# Or alternatively, you can use:\n",
    "# !pip install transformers[torch]\n",
    "\n",
    "# Now your original code should work\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load data\n",
    "df_real = pd.read_csv(\"fake_news_data/True.csv\")  # This might need to be changed to the correct file path\n",
    "df_fake = pd.read_csv(\"fake_news_data/Fake.csv\")\n",
    "\n",
    "df_fake[\"label\"] = 0\n",
    "df_real[\"label\"] = 1\n",
    "\n",
    "df = pd.concat([df_fake, df_real]).sample(frac=1).reset_index(drop=True)\n",
    "df[\"content\"] = df[\"title\"] + \" \" + df[\"text\"]\n",
    "X = list(df[\"content\"])\n",
    "y = list(df[\"label\"])\n",
    "\n",
    "# Rest of your code remains the same..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f6c9f9-613d-42bc-8a30-a700f65817ed",
   "metadata": {},
   "source": [
    "# Assistant\n",
    "This error occurs because you're missing the required dependencies for using the Hugging Face Transformer's Trainer class with PyTorch.\n",
    "\n",
    "The error message is quite clear: you need to install the `accelerate` library (version 0.26.0 or higher) which is required for the Trainer class to work properly with PyTorch.\n",
    "\n",
    "Would you like me to provide the corrected code?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652001b-0ad2-4ebb-b1ad-0af335602b84",
   "metadata": {},
   "source": [
    "# User\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f5936-34b7-4109-8f18-73738b63b582",
   "metadata": {},
   "source": [
    "# Assistant\n",
    "Before running your code, you need to install the required dependencies. Here's how to fix the issue:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ce7c56-aedb-4188-80f0-7167e54c6620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (2.7.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (0.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate>=0.26.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "# First, install the required dependencies\n",
    "!pip install \"accelerate>=0.26.0\"\n",
    "# Or alternatively, you can use:\n",
    "# !pip install transformers[torch]\n",
    "\n",
    "# Now your original code should work\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load data\n",
    "df_real = pd.read_csv(\"fake_news_data/True.csv\")  # This might need to be changed to the correct file path\n",
    "df_fake = pd.read_csv(\"fake_news_data/Fake.csv\")\n",
    "\n",
    "df_fake[\"label\"] = 0\n",
    "df_real[\"label\"] = 1\n",
    "\n",
    "df = pd.concat([df_fake, df_real]).sample(frac=1).reset_index(drop=True)\n",
    "df[\"content\"] = df[\"title\"] + \" \" + df[\"text\"]\n",
    "X = list(df[\"content\"])\n",
    "y = list(df[\"label\"])\n",
    "\n",
    "# Rest of your code remains the same..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6a9c4a0-ff6a-415d-98cc-c811bd7b72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, install the required dependencies - fix the quotation marks\n",
    "!pip install accelerate>=0.26.0\n",
    "# Or alternatively, you can use:\n",
    "# !pip install transformers[torch]\n",
    "\n",
    "# Now your original code should work\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load data\n",
    "df_real = pd.read_csv(\"fake_news_data/True.csv\")  # This might need to be changed to the correct file path\n",
    "df_fake = pd.read_csv(\"fake_news_data/Fake.csv\")\n",
    "\n",
    "df_fake[\"label\"] = 0\n",
    "df_real[\"label\"] = 1\n",
    "\n",
    "df = pd.concat([df_fake, df_real]).sample(frac=1).reset_index(drop=True)\n",
    "df[\"content\"] = df[\"title\"] + \" \" + df[\"text\"]\n",
    "X = list(df[\"content\"])\n",
    "y = list(df[\"label\"])\n",
    "\n",
    "# Rest of your code remains the same..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37eb1a-10bc-4387-b32e-6bea74ed2e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\utkar\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='13470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    9/13470 01:06 < 35:21:31, 0.11 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n",
    "# 5. Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",  # Changed from evaluation_strategy to eval_strategy for older versions\n",
    ")\n",
    "\n",
    "# 6. Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,                            # The model to train\n",
    "    args=training_args,                     # Training arguments\n",
    "    train_dataset=train_dataset,            # Training dataset\n",
    "    eval_dataset=test_dataset               # Evaluation dataset\n",
    ")\n",
    "\n",
    "# 8. Train the model\n",
    "trainer.train()\n",
    "\n",
    "# 9. Save the final model and tokenizer\n",
    "model.save_pretrained(\"saved_model\")\n",
    "tokenizer.save_pretrained(\"saved_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e5c8f8-1b77-4126-9f7c-9c560aa618e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
